---
title: "DataSci 306 Final Project"
author: "DataSci 306 Instructional Team"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Investigating the Internet Movie Database (IMDB)

The [Internet Movie Database (IMDb)]() contains information on millions of movies and television programs. They offer several [non-commercial use datasets](https://developer.imdb.com/non-commercial-datasets/) (documentation link). For this project we will analyze a **sample** of 100,000 titles from the IMDBb. 


## Part I: Preprocessing

* [Edit your `.gitignore` file](https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files) to ignore all files with the `.rda` extension. (Add and commit)
* Create a new file in the `data/` directory called "Preprocessing.Rmd". The remaining instructions in this section are to be completed in that file.
* Write a function that will load a table from the IMDb files in the `data/` directory.
  * The function should take the file name (without the ".csv.gz" portion) as an argument
  * The function should load the appropriate `.csv.gz` file.
  * Make sure that all "\\N" values (which IMDB uses to indicate missing values) are turned into proper NA values in R
  * The function should return the table.
* For each of the `.csv.gz` files, use your function to load the table, then save it into a variable (e.g. `name_basics <- preprocess("name_basics")`) and use the `write_rds` function (e.g., `write_rds(name_basics, "name_basics.rda")`.
* Run the function on all of the `*_sample.csv.gz` files to created processed `.rda` files.
* In your other files, you can load these using the `TABLE <- read_rds("data/FILENAME.rda")` function.

## Part II: EDA of individual tables

* For each of the 4 tables, perform basic exploratory data analysis. Report the following information:
  * For each quantitative column, provide some summary statistics
  * For any character columns, decided if they are actually representing factors/categorical data with a moderate number of columns. If so report the distributions for these variables.
  * Provide a plot for each table. Across all of the plots, try to show off the most possible different ggplot features (`geoms_` functions, `stat_` functions, coordinate systems, facets, use of several variables, annotations)
* For the `titles_basics` table
  * use two different variables to group and explore how `runtimeMinutes` varies for these different groups. Produce appropriate summaries.
  * How many titles are known for name that is different than the original release name?
  * Graph the conditional distributions of release year based on the previous results. Comment on any trends you observe.
* For the ratings, use the `cut` function to break the data into three groups based on the average ratings. Are higher rated titles rated more often or less often than lower rated titles? 
* For the names table, 
  * Count the number of titles each person is known for and plot this distribution.
  * investigate the age of cast members
      * Group the data into living and deceased cast members. 
      * For deceased cast members, provide a graph that shows the distribution of ages.
      * Do the same for living cast members.
* Find all the actors with first names "Tom", "Thomas", "Thom" or "Tomas". How many are there?
* How many titles use alliteration (i.e., all words in the title start with the same letter)?

```{r}
title_basics <- read_rds("data/title_basics_sample.rda")
title_ratings <- read_rds("data/title_ratings_sample.rda")
title_principals <- read_rds("data/title_principals_sample.rda")
name_basics <- read_rds("data/name_basics_sample.rda")
```

```{r title_basics}
title_basics %>%
  select(where(is.numeric)) %>%
  summary()

# genres and titleType seem to rerpesent categorical data
title_basics %>%
  select(where(is.character)) %>%
  summarise(across(everything(), n_distinct))

title_basics %>%
  count(titleType, sort = TRUE)

title_basics %>%
  count(genres, sort = TRUE)

title_basics %>%
  filter(!is.na(runtimeMinutes), runtimeMinutes < 300, !is.na(titleType)) %>%
  ggplot(aes(x = titleType, y = runtimeMinutes)) +
  geom_boxplot(fill = "lightblue") +
  coord_flip() +
  labs(
    title = "Runtime by Title Type",
    x = "Title Type",
    y = "Runtime (minutes)"
  ) +
  theme_minimal()

# part 1
title_basics %>%
  filter(!is.na(runtimeMinutes)) %>%
  group_by(titleType, isAdult) %>%
  summarise(
    mean_runtime = mean(runtimeMinutes, na.rm = TRUE),
    median_runtime = median(runtimeMinutes, na.rm = TRUE),
    count = n(),
    .groups = "drop"
  )

# part 2
diff_titles <- title_basics %>%
  filter(!is.na(primaryTitle), !is.na(originalTitle)) %>%
  filter(primaryTitle != originalTitle)

n_diff_titles <- nrow(diff_titles)
paste("Part B: number of titles with different primary and original titles:", n_diff_titles)
# 7244

# part 3
title_basics <- title_basics %>%
  mutate(different_name = primaryTitle != originalTitle)

ggplot(title_basics %>% filter(!is.na(startYear)), aes(x = startYear, fill = different_name)) +
  geom_histogram(binwidth = 5, position = "identity", alpha = 0.6) +
  scale_fill_manual(values = c("steelblue", "tomato"), labels = c("Same Name", "Different Name")) +
  labs(
    title = "Distribution of Start Year by Title Name Type",
    x = "Start Year",
    y = "Number of Titles",
    fill = "Title Match"
  ) +
  theme_minimal()

# alliteration question
library(stringr)

alliteration_titles <- title_basics %>%
  filter(!is.na(primaryTitle)) %>%
  mutate(
    words = str_split(primaryTitle, "\\s+"),
    all_start_same = map_lgl(words, ~ {
      first_letters <- str_sub(.x, 1, 1) %>% str_to_upper()
      length(first_letters) > 1 && all(first_letters == first_letters[1])
    })
  ) %>%
  filter(all_start_same)

n_alliteration_titles <- nrow(alliteration_titles)
paste(n_alliteration_titles, "titles use alliteration")

```
Part B: number of titles with different primary and original titles: 7244

Observation for Part C: The majority of titles retain the same name as their original release title.

Alliteration: 2650 titles use alliteration


```{r title_ratings}
# numerical data
title_ratings %>%
  select(where(is.numeric)) %>%
  summary()

# title_ratings has no categorical data

title_ratings <- title_ratings %>%
  mutate(rating_group = cut(
    averageRating,
    breaks = c(0, 5, 7, 10),
    labels = c("Low", "Medium", "High"),
    include.lowest = TRUE
  ))


rating_summary <- title_ratings %>%
  group_by(rating_group) %>%
  summarise(
    mean_votes = mean(numVotes),
    count = n(),
    .groups = "drop"
  )

rating_summary

# plot
ggplot(rating_summary, aes(x = rating_group, y = mean_votes, fill = rating_group)) +
  geom_col() +
  labs(
    title = "Average Number of Votes by Rating Group",
    x = "Rating Group",
    y = "Mean Number of Votes"
  ) +
  theme_minimal() +
  theme(legend.position = "none")


```
Higher rated movies are rated more often tha lower rated movies.

```{r title_principals}
title_principals %>%
  select(where(is.numeric)) %>%
  summary()

## category seems to be the only meaningful cateogorical variable
title_principals %>%
  select(where(is.character)) %>%
  summarise(across(everything(), n_distinct))

title_principals %>%
  count(category, sort = TRUE)

## plot
ggplot(title_principals, aes(x = category, y = ordering)) +
  stat_summary(fun = median, geom = "point", size = 3, color = "steelblue") +
  coord_flip() +
  labs(
    title = "Median Ordering by Category",
    x = "Principal Category",
    y = "Ordering"
  ) +
  theme_minimal()

```

```{r name-basics}
## numerical
name_basics %>%
  select(where(is.numeric)) %>%
  summary()

## no seemingly meaningful categorical variable

## plot 
profession_counts <- name_basics %>%
  filter(!is.na(primaryProfession)) %>%
  separate_rows(primaryProfession, sep = ",") %>%
  count(primaryProfession, sort = TRUE)

profession_counts %>%
  slice_max(n, n = 10) %>%
  ggplot(aes(x = reorder(primaryProfession, n), y = n)) +
  geom_col(fill = "mediumpurple") +
  coord_flip() +
  labs(
    title = "Top 10 Most Common Primary Professions",
    x = "Profession",
    y = "Count"
  ) +
  theme_minimal()

## number of titles each person is known for
name_basics <- name_basics %>%
  filter(!is.na(knownForTitles)) %>%
  mutate(num_titles = str_count(knownForTitles, ",") + 1)

ggplot(name_basics, aes(x = num_titles)) +
  geom_bar(fill = "steelblue") +
  labs(
    title = "Number of Known Titles per Person",
    x = "# of Known Titles",
    y = "Count"
  ) +
  theme_minimal()

## tom, thom, tomas, thomas 
tom <- name_basics %>%
  filter(str_detect(primaryName, regex("^(T(h)?om(as)?)\\b", ignore_case = TRUE)))
n_toms <- nrow(tom)
cat("Number of actors with names starting with Tom, Thomas, Thom, or Tomas:", n_toms)
# 3290 actors

## age of cast members
name_basics <- name_basics %>%
  mutate(
    is_deceased = !is.na(deathYear),
    age = ifelse(is_deceased, deathYear - birthYear, 2025 - birthYear)
  ) %>%
  filter(!is.na(age), age > 0, age < 120) # because there was outliers for alive people

#deceased
ggplot(filter(name_basics, is_deceased), aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "tomato", color = "white") +
  labs(
    title = "Age at Death of Deceased Individuals",
    x = "Age at Death",
    y = "Count"
  ) +
  theme_minimal()

#alive
ggplot(filter(name_basics, !is_deceased), aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "seagreen", color = "white") +
  labs(
    title = "Current Age of Living Individuals",
    x = "Age (as of 2025)",
    y = "Count"
  ) +
  theme_minimal()

```

## Part III: Pivoting

* Create a new version of the `titles_basics` table that has one row for each title-genre combination. See the `separate_rows` function for a useful too here.

```{r 3a}
#colnames(title_basics)
titles_basics_long = title_basics %>%
  separate_rows(genres, sep = ",")
```
* Using that table, create a line plot of the count different genres over time (you may limit this to the most common genres if you wish).
```{r 3b}
#pulls top 5 genres
top_genres = titles_basics_long %>%
  count(genres, sort = TRUE) %>%
  top_n(5, n) %>%
  pull(genres)

genre_trends = titles_basics_long %>%
  filter(genres %in% top_genres) %>%
  filter(!is.na(startYear) & startYear != "\\N") %>%
  mutate(startYear = as.integer(startYear)) %>%
  group_by(startYear, genres) %>%
  summarise(count = n(), .groups = "drop")

ggplot(genre_trends, aes(x = startYear, y = count, color = genres)) +
  geom_line(size = 0.5) +
  labs(title = "Top 5 Genre Trends Over Time",
       x = "Year",
       y = "Number of Titles",
       color = "Genre")
```
* Use the `model.matrix` function in the following way: `model.matrix(yourtalltable, ~ genre - 1)` to create a wide table with one column for each genre. Use this table to find the most common pair of genres (hint: use the `cor` function or produce facet plots)
```{r 3c}
genre_matrix = model.matrix(~ genres - 1, data = titles_basics_long)
genre_cors = cor(genre_matrix)
#doesnt include genreNA
top_genre_pairs = as.data.frame(as.table(genre_cors)) %>%
  filter(Var1 != Var2) %>%
  filter(!str_detect(Var1, "NA") & !str_detect(Var2, "NA")) %>%
  mutate(pair = pmap_chr(list(Var1, Var2), ~ paste(sort(c(..1, ..2)), collapse = " & "))) %>%
  distinct(pair, .keep_all = TRUE) %>%
  select(pair, correlation = Freq) %>%
  arrange(desc(correlation)) 

head(top_genre_pairs, 5)
```
The genresFilm-Noir and genresMusical are the most positively correlated with a correlation of -0.001197310.

## Part IV: Joining Tables

* Join the table with one title-genre per row from the previous section with the ratings table.
  * What is the highest rated genre? What is the lowest rated genre?
  * Using stacked bar charts, investigate the proportions of different genres over time. Are any incresing or decreasing? Use factor functions to help make the plots easier to read.
  
```{r 4a}
#colnames(titles_basics_long)
#colnames(title_ratings)

# joins the two tables
titles_with_ratings = titles_basics_long |>
  inner_join(title_ratings, by = "tconst")

mean_votes = titles_with_ratings |> 
  filter(!is.na(genres)) |>
  group_by(genres) |>
  summarise(mean_votes_per_genre = mean(numVotes, na.rm = TRUE)) |>
  arrange(desc(mean_votes_per_genre)) 
  
  head(mean_votes,1) # genre with most votes
  tail(mean_votes,2) # bottom 2 genres
  
titles_with_ratings |>
  filter(startYear != "\\N") |>
  mutate(startYear = as.integer(startYear)) |>
  group_by(startYear, genres) |>
  summarize(n = n()) |>
  group_by(startYear) |>
  mutate(prop = n / sum(n)) |>
  ggplot(aes(x = startYear, y = prop, fill = fct_lump(genres, n = 8))) +   #lump rare genres into "Other"
  geom_col() +
  labs(title = "Genre proportions over time",
       x = "Year", y = "Proportion",
       fill = "Genre") 

```
The highest rated genre is Sci-Fi. The lowest rated genre is NA. The lowest rated genre that isn't NA is Adult. Looking at genre proportions over time, the proportion of short films are decreasing while the proportion of animation is increasing.   

* Join the `title_basics` with the ratings table. Have the number of ratings changed over time (based on release year)? Display graphically but also answer with numerical results.
```{r 4b}
#colnames(title_basics)
#colnames(title_ratings)

#join the tables
titles_with_ratings_short = title_basics |>
  inner_join(title_ratings, by = "tconst")

votes_per_year = titles_with_ratings_short |>
  filter(startYear != "\\N") |>
  mutate(startYear = as.integer(startYear)) |>
  group_by(startYear) |>
  summarise(total_votes = sum(numVotes,na.rm = TRUE)) 

votes_per_year |>
  ggplot(aes(x = startYear, y = total_votes)) +
  geom_col() +
  labs(title = "Total Votes per Year",
       x = "Year", y = "Total Votes") 

votes_per_year |>
  arrange(desc(total_votes)) |>
  head(10)    #most rated 10 years

votes_per_year |>
  arrange(total_votes) |>
  head(10)    #least rated 10 years

votes_per_year |>
  mutate(startYear = as.integer(startYear)) |>
  filter(startYear > 2011) |>
  summarise(mean_votes = mean(total_votes))

```
The number of ratings increased until 2011 with 7004647	ratings. However, the number of ratings is dropping since with an average of 2859065	per year after 2011.  

* Join the names with the ratings and the principals table. 
  * Group by individual people, find the top ten people based on the median rating of the titles they appear in.
  * Find the proportions of genres for the the titles that include the top 10 rated principals.
  * Graph ratings against years. What trends do you see?
```{r 4c}
colnames(name_basics)
colnames(title_ratings)
colnames(title_principals)

#join the 3 tables
names_ratings_princ = title_principals |>
  inner_join(name_basics, by = "nconst") |>
  inner_join(title_ratings, by = "tconst")

#top ten people based on the median rating of the titles they appear in
top_10_people = names_ratings_princ |>
  group_by(nconst, primaryName) |>
  summarise(med_rating = median(numVotes, na.rm = TRUE)) |>
  arrange(desc(med_rating)) |>
  head(10)

top_10_people

genre_proportions = title_principals |>
  filter(nconst %in% top_10_people$nconst) |>
  inner_join(titles_basics_long, by = "tconst", relationship = "many-to-many") |> 
  group_by(genres) |>
  summarize(count = n()) |>
  mutate(proportion = count / sum(count)) #Calculate proportions of genres for the top 10 rated principals

genre_proportions

#Plot the ratings against years
names_ratings_princ |>
  filter(nconst %in% top_10_people$nconst) |>
  inner_join(titles_basics_long, by = "tconst", relationship = "many-to-many") |>
  ggplot(aes(x = startYear, y = averageRating)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Ratings of Titles Featuring Top 10 Rated Principals Over Time",
       x = "Release Year",
       y = "Average Rating") +
  theme_minimal()



```
The ratings of the titles that these top 10 people were in are increasing as the release years increase.

* Create a table with one row for each person in the `name_basics` table and title they are known for. Join this to the ratings table to get the ratings of the "known for" films. Find the person (or people) who have the highest median known for rating.

```{r 4d}
known_for_titles = name_basics |>
  separate_rows(knownForTitles, sep = ",") |>
  inner_join(title_basics, by = c("knownForTitles" = "tconst")) |>
  select(nconst, primaryName, knownForTitles)

known_for_titles

#people who have the highest known for rating
known_for_titles |>
  inner_join(title_ratings,  by = c("knownForTitles" = "tconst")) |> #join with ratings table
  group_by(nconst, primaryName) |>
  summarize(median_rating = median(averageRating, na.rm = TRUE), .groups = "drop") |>
  filter(median_rating == max(median_rating))
```

## Part V: Profiling and Parallel Processing

* These are large data sets (and yet only a sample of the entire IMDb!), so it make sense spend some time improving our code.
* Pick one or more of the previous problems and profile the performance of that piece. Write up your findings. If you see any opportunities to improve performance, feel fee to implement than and share the results.

For profiling, I selected the task that calculates the average rating by year. This operation groups the data by the year a movie was released and then calculates the mean rating for each group. When I profiled this task using system.time(), I found that it took a significant amount of time to complete, likely because of the large number of unique years and the overall size of the IMDb data set. Since grouping and summarizing across such a big data set is computationally intensive, this makes sense. To improve the performance, a good next step would be to switch to a faster grouping method, like using data.table.

```{r}
# Step 1: Profiling average rating by year
system.time({
  avg_rating_by_year <- imdb_data %>%
    group_by(year) %>%
    summarise(avg_rating = mean(rating, na.rm = TRUE))
})
```

* Select a previous computation that could be improved using parallelization and implement a parallelization solution. Using `system.time` show that parallelization improves performance.

For parallelization, I selected the task that calculates the average rating by top star. This task goes through each unique top-billed actor or actress and calculates the average movie rating for their movies. Because each starâ€™s data is independent of the others, it is a good candidate for parallel computing. By using multiple cores, each star's data can be processed at the same time, speeding up the task. I used parLapply from the parallel package to parallelize this operation, and compared the execution time using system.time() to confirm that performance improved.

```{r}
# Step 2: Parallelizing average rating by top star
library(parallel)
system.time({
  num_cores <- detectCores() - 1
  cl <- makeCluster(num_cores)
  clusterExport(cl, list("imdb_data"))
  
  avg_rating_by_top_star <- parLapply(cl, unique(imdb_data$top_star), function(star) {
    imdb_data %>%
      filter(top_star == star) %>%
      summarise(avg_rating = mean(rating, na.rm = TRUE))
  })
  
  stopCluster(cl)
})
```

* One task we performed involved counting items in strings separated by commas. Propose two different functions that could perform this tasks. 
Compare them using bench marking. Which version would you recommend?

For the comma-separated genre counting, I proposed two different functions. The first function uses strsplit() to split each genre string by commas and then length() to count how many genres each movie has. The second function uses a tidyverse method where separate_rows() splits the genres into multiple rows and group_by() with summarise() counts the number of genres per movie. I benchmarked both methods using the bench package. Based on the results, the strsplit() method was significantly faster and more memory-efficient. Because the task only requires simple counting and not full restructuring, I would recommend using the strsplit() method.

```{r}
# Step 3: Benchmarking two methods for counting comma-separated genres
library(bench)

# Method 1: Using strsplit and length
count_genres_split <- function(data) {
  sapply(strsplit(data$genres, ","), length)
}

# Method 2: Using tidyverse separate_rows
count_genres_separate <- function(data) {
  data %>%
    separate_rows(genres, sep = ",") %>%
    group_by(movie_id) %>%
    summarise(genre_count = n())
}

# Benchmarking both methods
bench::mark(
  split_method = count_genres_split(imdb_data),
  separate_method = count_genres_separate(imdb_data)
)
```

## Part VI: Shiny Applications

### Application 1

Using results from the previous section, create a shiny application that allows users to interact with the with the IMDb data. The application should use both interactive graphs and at least 3 widgets.


### Application 2

In the principals table, there is a `category` column. Use this column as a primary filter to allow users to then select specific job categories. After select the specific job categories, display information from another table.

## Extra Credit: 6 Degrees of Kevin Bacon

Create an app to allow users to play [Six Degrees of Kevin Bacon](https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon#:~:text=Six%20Degrees%20of%20Kevin%20Bacon%20or%20Bacon's%20Law%20is%20a,ultimately%20leads%20to%20prolific%20American).

Create a Shiny application where a person can type the primary title of movie or TV show. Then have app show all the people who had a role in the show. Let the user select a person in that cast and show all other people who have been in a title with that person. Repeat up to 6 times. If "Kevin Bacon" (`nconst == 'nm0000102'`) ever appears in the list, let the player know they have won! If they click more than 6 times, let them know they have lost.


